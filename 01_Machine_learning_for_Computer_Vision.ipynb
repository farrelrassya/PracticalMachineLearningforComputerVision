{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZYyhlCt1uf6lxEtDFDg7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farrelrassya/PracticalMachineLearningforComputerVision/blob/main/01_Machine_learning_for_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. Chapter 01 - Machine Learning for Computer Vision\n",
        "\n",
        "Imagine that you are sitting in a garden, observing what’s going on around you. There are two systems in your body that are at work: your eyes are acting as sensors and creating representations of the scene, while your cognitive system is making sense of what your eyes are seeing. Thus, you might see a bird, a worm, and some movement and realize that the bird has walked down the path and is eating a worm. see figure1.1"
      ],
      "metadata": {
        "id": "-35JnR_TMCN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/farrelrassya/PracticalMachineLearningforComputerVision/main/figure1.1.png\" width=\"700\" height=\"500\">\n"
      ],
      "metadata": {
        "id": "WTD-GAEBMrjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computer vision tries to imitate human vision capabilities by providing methods for\n",
        "image formation (mimicking the human sensory system) and machine perception\n",
        "(mimicking the human cognitive system). Imitation of the human sensory system is\n",
        "focused on hardware and on the design and placement of sensors such as cameras."
      ],
      "metadata": {
        "id": "1fMnqQFFW23o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning\n",
        "If you were reading a book on computer vision in the early 2010s, the methods used\n",
        "to extract information from photographs would not have involved machine learning.\n",
        "Instead, you would have been learning about denoising, edge finding, texture detection, and morphological (shape-based) operations. With advancements in artificial intelligence (more specifically, advances in machine learning), this has changed. Artificial intelligence (AI) explores methods by which computers can mimic human capabilities. Machine learning is a subfield of AI that teaches computers to do this by showing them a large amount of data and instructing them to learn from it. Expert systems is another subfield of AI—expert systems teach computers to mimic human capabilities by programming the computers to follow human logic. Prior to the 2010s, computer vision tasks like image classification were commonly done by building bespoke image filters to implement the logic laid out by experts. Nowadays, image classification is achieved through convolutional networks, a form of deep learning\n",
        "(see Figure 1-3)."
      ],
      "metadata": {
        "id": "h0pQh2cZXNmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/farrelrassya/PracticalMachineLearningforComputerVision/main/figure1.3.png\" width=\"700\" height=\"500\">\n"
      ],
      "metadata": {
        "id": "6WQ733M0YRDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an expert system approach, on the other hand, we would start by interviewing a\n",
        "human botanist on how they classify flowers. If the botanist explained that bellis perennis (the scientific name for a daisy) consists of white elongated petals around a yellow center and green, rounded leaves, we would attempt to devise image processing filters to match these criteria. For example, we’d look for the prevalence of white, yellow, and green in the image. Then we’d devise edge filters to identify the borders ofthe leaves and matched morphological filters to see if they match the expected rounded shape. We might smooth the image in HSV (hue, saturation, value) space to determine the color of the center of the flower as compared to the color of the petals.Based on these criteria, we might come up with a score for an image that rates the\n",
        "likelihood that it is a daisy. Similarly, we’d design and apply different sets of rules for roses, tulips, sunflowers, and so on. To classify a new image, we’d pick the category whose score is highest for that image. This description illustrates the considerable bespoke work that was needed to create image classification models. This is why image classification used to have limited\n",
        "applicability."
      ],
      "metadata": {
        "id": "bK1n5duFYp_0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js10nmZHMAtF"
      },
      "outputs": [],
      "source": []
    }
  ]
}